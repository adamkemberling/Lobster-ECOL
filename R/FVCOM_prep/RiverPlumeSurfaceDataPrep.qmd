---
title: "River Plume FVCOM Data Validation Set"
description: | 
  Extracting Surface and Bottom FVCOM Conditions for the CBASS Survey
date: "Updated on: `r Sys.Date()`"
format: 
  html:
    code-fold: true
    code-tools: true
    df-print: kable
    self-contained: true
execute: 
  echo: true
  warning: false
  message: false
  fig.align: "center"
  comment: ""
---

```{r}

####. packages. ####
library(gmRi)
library(tidyverse)
library(sf)
library(rnaturalearth)
library(fvcom)
library(ncdf4)
library(patchwork)

# Set the theme
theme_set(theme_bw() + map_theme())

# Project paths
lob_ecol_path <- cs_path("mills", "Projects/Lobster ECOL")
fvcom_path <- cs_path("res", "FVCOM/Lobster-ECOL")
poly_paths <- cs_path("mills", "Projects/Lobster ECOL/Spatial_Defs")

# Shapefiles
new_england <- ne_states(
  country = "united states of america", 
  returnclass = "sf") %>%
  filter(postal %in% c("ME", "MA", "CT", "NY", "VT", "NH", "RI"))
canada <-  ne_states(
  country = "canada", 
  returnclass = "sf")

# Medium-resolution shoreline
shore <- st_read(str_c(
  cs_path("res", "Shapefiles/us_medium_shoreline"),
  "us_medium_shoreline.shp"
))


# These can be plotted
# Make a box to use when cropping based on an xlim and ylim pair
make_cropbox <- function(xlims, ylims){
  sfc <- st_sfc(st_polygon(list(
    rbind(c(xlims[[1]], ylims[[1]]),  
          c(xlims[[1]], ylims[[2]]), 
          c(xlims[[2]], ylims[[2]]), 
          c(xlims[[2]], ylims[[1]]), 
          c(xlims[[1]], ylims[[1]])))))
  sfc <- st_as_sf(sfc)
  return(sfc)
}


```




```{r}
#| label: load-daily-fvcom
# Loading FVCOM

# Get some file names
fvcom_surfbot_files <- setNames(
  list.files(fvcom_path, full.names = T, pattern = ".nc"),
  str_remove(list.files(fvcom_path, full.names = F, pattern = ".nc"), ".nc"))

# Open one
gom3_early <- nc_open(fvcom_surfbot_files[[1]])

# Get the mesh itself as a simple feature collection
gom3_mesh <- get_mesh_geometry(gom3_early, what = 'lonlat') 


# Table of lat/lon coordinates for each node
gom3_coords <- data.frame(
    "lon" = ncvar_get(gom3_early, "lon"),
    "lat" = ncvar_get(gom3_early, "lat")) %>% 
  mutate(node_id = row_number(), 
         .before = "lon")

# What crs is the mesh in? (or does ben use)
st_crs(gom3_mesh)
```


```{r}
#| label: export the shapefile to use as mask
#| eval: false  



gom3_hull <- gom3_mesh %>% st_union() 
gom3_hull %>% ggplot() + geom_sf() 
gom3_mesh %>% st_write(here::here("local_data/mesh_shapefiles/gom3_mesh.geojson"))
gom3_hull %>% st_write(here::here("local_data/mesh_shapefiles/gom3_mesh_hull.geojson"))
```




Gameplan:

 1. Set up 1km grid (in crs that matches FVCOM grid)
 2. Triangulate each grid cell center within the FVCOM mesh
 3. Use that lookup table to pull data
 4. Interpolate
 5. export as mult-variable netcdf
 
 
 
### Set up grid

Felipe needs a modest resolution, and suggested 1k. This will end up being a higher resolution in offshore areas than FVCOM, but a lower resolution in nearshore areas. This is fine, we can revisit later if needed.

```{r}
#| label: build the regular grid

# Make Bounding Box that spans from Long Island Sound to New Brunswick
study_area_bbox <- make_cropbox(
  xlims = c(-72, -63), 
  ylims = c(41.15, 46)) %>% 
  st_set_crs(st_crs(4326)) #%>% 
  #st_transform(st_crs(32619))
  

# Make the map
ggplot() +
  geom_sf(data = new_england) +
  geom_sf(data = canada) +
  geom_sf(data = study_area_bbox, fill = "transparent", color = "black", linewidth = 1) +
  coord_sf(xlim = c(-73, -62), ylim = c(41, 45.9))



# # Create a 1 km regular grid inside the projected bounding box
# grid_1k <- st_make_grid(
#   study_area_bbox,
#   cellsize = 1000,     # 1000 meters = 1 km
#   square = TRUE,
#   what = "centers"     # for a table of points instead of polygons
# )
# 
# # Now we can transform back and load the coordinate in:
# grid_1k <- st_transform(grid_1k, st_crs(4326))
# grid_1k = bind_cols(grid_1k, as_tibble(st_coordinates(grid_1k))) %>% 
#   select(lon = X, lat = Y, geometry = `...1`) %>% 
#   st_as_sf()



# Create a roughly 1km Grid in 4326
# Create a 1 km regular grid inside the projected bounding box
grid_1k <- st_make_grid(
  study_area_bbox,
  cellsize = 0.009,     # 1000 meters = 1 km
  square = TRUE,
  what = "centers")     # for a table of points instead of polygons
grid_1k = bind_cols(grid_1k, as_tibble(st_coordinates(grid_1k))) %>%
  select(lon = X, lat = Y, geometry = `...1`) %>%
  st_as_sf()


# Map that out
ggplot() +
  geom_sf(data = grid_1k, size = .01, alpha = 0.2) +
  geom_sf(data = new_england) +
  geom_sf(data = canada) +
  geom_sf(data = study_area_bbox, fill = "transparent", color = "orange", linewidth = 1) +
  coord_sf(xlim = c(-73, -61), ylim = c(40.7, 45.9))

```


Find which cells are within the FVCOM mesh, many are over land and so we can discard them.

```{r}
# grid_slim <- st_join(
#   st_transform(grid_1k, st_crs(gom3_mesh)) %>% st_as_sf(),
#   gom3_mesh, 
#   st_within) %>% 
#   drop_na(elem)
# 
# # Place the coordinates 
# grid_slim <- bind_cols(
#   grid_slim, 
#   rename(as_tibble(st_coordinates(grid_slim)), lon = X, lat = Y))
# 
# # Plot those
# ggplot() + 
#   geom_sf(data = grid_slim, shape = 3, size = 0.15, alpha = 0.5) +
#   geom_sf(data = new_england) +
#   coord_sf(xlim = c(-70.75, -68), ylim = c(43.25, 45))
```


### Get the coordinates and weights for those nodes

The following function will take set of points of class `sf` that also contains `lat` & `lon` columns and it will perform a number of steps to prepare it as a lookup table for returning linearly interpolated FVCOM timeseries.


```{r}

# Function to add the linear interpolation weights based on node coordinates
fvcom_point_interp_weighting <- function(pts_sf, fvcom_mesh){

    # Identify the triangles that overlap each point:
    # Use st_join to assign elem to the points and their we're looking up
    pts_assigned <- st_join(
      st_transform(pts_sf, st_crs(fvcom_mesh)),
      gom3_mesh, 
      join = st_within) %>% 
      drop_na(elem)
  
    
    # Iterate over the rows to add weights:
    pts_weighted <- pts_assigned %>% 
     purrr::pmap_dfr(function(elem, p1, p2, p3, lon, lat,  ...){
    
      # Subset the relevant triangle from st_join info
      triangle_match <- fvcom_mesh[elem,]
      
      # Build matrices for point to interpolate & of surrounding points:
    
      # Matrix for triangle
      # Use the triangles node coordinates from the sf geometries
      node_vertices <- t(st_coordinates(triangle_match[1,])[1:3,1:3])
      
      # Make matrix from the points:
      point_coords <- matrix(
        c(lon, lat, 1), 
        nrow = 3)
      
      #### For Linear Interpolation:
      
      # Get inverse of the matrix
      inverse_coordmat <- solve(node_vertices)
      
      # Solve for the weights
      node_wts <- inverse_coordmat %*% point_coords %>%
        t() %>% 
        as.data.frame() %>% 
        setNames(c("p1_wt", "p2_wt", "p3_wt"))
      
      # Return with dataframe
      tibble(
        "lon" = lon, "lat" = lat,
        "elem" = elem, "p1" = p1, 
        "p2" = p2, "p3" = p3) %>% 
        bind_cols(node_wts)
    
    
    })
    # End Rowwise
    return(pts_weighted)
}


```




```{r}

# Get the mesh indexing information and weighting information to perform interpolations
grid_1k_weighted <- fvcom_point_interp_weighting(
  pts_sf = grid_1k, 
  fvcom_mesh = gom3_mesh)
```




# Export, move to python

```{r}
write_csv(
  grid_1k_weighted,
  here::here("local_data/plumes/grid_1km_fvcom_indices.csv"))
```


